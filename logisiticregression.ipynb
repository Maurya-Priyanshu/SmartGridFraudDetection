{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, confusion_matrix, \\\n",
    "    precision_recall_fscore_support, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Conv2D\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "epochs_number = 1  # number of epochs for the neural networks\n",
    "test_set_size = 0.1  # percentage of the test size comparing to the whole dataset\n",
    "oversampling_flag = 0  # set to 1 to over-sample the minority class\n",
    "oversampling_percentage = 0.2  # percentage of the minority class after the oversampling comparing to majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\e'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\e'\n",
      "C:\\Users\\PRIYANSHUMAURYA\\AppData\\Local\\Temp\\ipykernel_24292\\3290770298.py:2: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  rawData = pd.read_csv('C:\\electricity theft detection\\preprocessedR.csv')\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    rawData = pd.read_csv('C:\\electricity theft detection\\preprocessedR.csv')\n",
    "\n",
    "    # Setting the target and dropping the unnecessary columns\n",
    "    y = rawData[['FLAG']]\n",
    "    X = rawData.drop(['FLAG', 'CONS_NO'], axis=1)\n",
    "\n",
    "    print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
    "    print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
    "    print('Total Consumers:                     ', y.shape[0])\n",
    "    print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n",
    "\n",
    "    # columns reindexing according to dates\n",
    "    X.columns = pd.to_datetime(X.columns)\n",
    "    X = X.reindex(X.columns, axis=1)\n",
    "\n",
    "    # Splitting the dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y['FLAG'], test_size=test_set_size, random_state=0)\n",
    "    print(\"Test set assuming no fraud:           %.2f\" % (y_test[y_test == 0].count() / y_test.shape[0] * 100), \"%\\n\")\n",
    "\n",
    "    # Oversampling of minority class to encounter the imbalanced learning\n",
    "    if oversampling_flag == 1:\n",
    "        over = SMOTE(sampling_strategy=oversampling_percentage, random_state=0)\n",
    "        X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "        print(\"Oversampling statistics in training set: \")\n",
    "        print('Normal Consumers:                    ', y_train[y_train == 0].count())\n",
    "        print('Consumers with Fraud:                ', y_train[y_train == 1].count())\n",
    "        print(\"Total Consumers                      \", X_train.shape[0])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_test, prediction):\n",
    "    print(\"Accuracy\", 100 * accuracy_score(y_test, prediction))\n",
    "    print(\"RMSE:\", mean_squared_error(y_test, prediction, squared=False))\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, prediction))\n",
    "    print(\"F1:\", 100 * precision_recall_fscore_support(y_test, prediction)[2])\n",
    "    print(\"AUC:\", 100 * roc_auc_score(y_test, prediction))\n",
    "    print(confusion_matrix(y_test, prediction), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, X_test, y_train, y_test):\n",
    "    print('Logistic Regression:')\n",
    "    '''\n",
    "    # Parameters selection \n",
    "    param_grid = {'C': [0.1,1,10,100],'solver': ['newton-cg', 'lbfgs']}\n",
    "    grid = GridSearchCV(LogisticRegression(max_iter=1000,random_state=0), param_grid=param_grid, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    df = pd.DataFrame(grid.cv_results_)\n",
    "    print(df[['param_C', 'param_solver', 'mean_test_score', 'rank_test_score']])\n",
    "    '''\n",
    "    model = LogisticRegression(C=1000, max_iter=1000, n_jobs=-1, solver='newton-cg')\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    results(y_test, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRIYANSHUMAURYA\\AppData\\Local\\Temp\\ipykernel_24292\\3290770298.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print('Normal Consumers:                    ', y[y['FLAG'] == 0].count()[0])\n",
      "C:\\Users\\PRIYANSHUMAURYA\\AppData\\Local\\Temp\\ipykernel_24292\\3290770298.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print('Consumers with Fraud:                ', y[y['FLAG'] == 1].count()[0])\n",
      "C:\\Users\\PRIYANSHUMAURYA\\AppData\\Local\\Temp\\ipykernel_24292\\3290770298.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(\"Classification assuming no fraud:     %.2f\" % (y[y['FLAG'] == 0].count()[0] / y.shape[0] * 100), \"%\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Consumers:                     36677\n",
      "Consumers with Fraud:                 3579\n",
      "Total Consumers:                      40256\n",
      "Classification assuming no fraud:     91.11 %\n",
      "Test set assuming no fraud:           90.78 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy 90.66070541480377\n",
      "RMSE: 0.3056025946420649\n",
      "MAE: 0.09339294585196224\n",
      "F1: [95.04480759 18.96551724]\n",
      "AUC: 55.2596044999834\n",
      "[[3606   49]\n",
      " [ 327   44]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRIYANSHUMAURYA\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression:')\n",
    "'''\n",
    "# Parameters selection \n",
    "param_grid = {'C': [0.1,1,10,100],'solver': ['newton-cg', 'lbfgs']}\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000,random_state=0), param_grid=param_grid, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "print(df[['param_C', 'param_solver', 'mean_test_score', 'rank_test_score']])\n",
    "'''\n",
    "model = LogisticRegression(C=1000, max_iter=1000, n_jobs=-1, solver='newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "results(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = {\"model\": model}\n",
    "with open('saved_model.pkl','wb')as file:\n",
    "    pickle.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 90.66070541480377\n",
      "RMSE: 0.3056025946420649\n",
      "MAE: 0.09339294585196224\n",
      "F1: [95.04480759 18.96551724]\n",
      "AUC: 55.2596044999834\n",
      "[[3606   49]\n",
      " [ 327   44]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRIYANSHUMAURYA\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('saved_model.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "model = data[\"model\"]\n",
    "prediction = model.predict(X_test)\n",
    "results(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "X_test.head().to_csv(\"Customer1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row=X_test.iloc[10]\n",
    "\n",
    "row_as_dataframe = pd.DataFrame(row).transpose()\n",
    "model.predict(row_as_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
